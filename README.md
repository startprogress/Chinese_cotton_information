## 文件结构介绍
* ccqsc:　包含爬虫的代码
* data：　默认存放文件的文件夹,程序运行时自动创建
* scrapy.cfg:　项目配置文件
* build.sh:　环境搭建的shell脚本
* README.md： 项目阅读说明

## 环境准备
* 进入项目根目录 ccqsc/
* 执行: sh build.sh 可能花费时间较长，请耐心等待
* 注意事项：保证有sudo权限或以root身份登录操作系

## 使用说明
* 首先参照环境准备，确认scrapy安装成功
* 打开文件ccqsc，命令就在根目录ccqsc/ 路径下执行
* 命令主体： scrapy crawl ccqsc ，此时将在ccqsc/data/目录下载当天的文件 
* 参数选项一：  -a date="你要选择的日期或日期范围",格式YYYY-MM-DD或YYYY-MM-DD~YYYY-MM-DD
* 参数选项二：  -a path="你要选择的下载路径"
* 举例说明一：  scrapy crawl ccqsc  -a date="2016-09-01" 表示将下载2016年9月1日的所有批次的数据
* 举例说明二：  scrapy crawl ccqsc  -a date="2016-09-01~2017-01-10" -a path="/data2/"  表示将下载，16年9月1日到17年1月10日（均含）这个范围内的数据，且把路径改为根目录下的data2文件夹内

## 下载文件的文件结构
* 每次下载，都会在路径下（如果没有用path参数修改路径则为默认路径ccqsc/data/）创建一个以日期或日期范围命名的文件夹，所有下载的文件都在这个目录，下载的文件则以它的批次号命名

* 举例说明三： 以scrapy crawl ccqsc  -a date="2016-09-01~2017-01-10" -a path="/data2/"这条命令为例，这次下载的所有文件都以自己的批次号命名，然后存放在/data/2/2016-09-01~2017-01-10/ 目录下

* 关于json文件更新：每次执行时，如果发现该条命令要创建的文件夹（以日期或日期范围命名）存在，则将里面的文件全部删除，重新下载。
