## 文件结构介绍
* ccqsc:　包含爬虫的代码
* data：　默认存放下载文件的文件夹,程序运行时自动创建
* scrapy.cfg:　项目配置文件
* build.sh:　搭建环境的shell脚本
* README.md： 使用说明

## 环境准备
* 执行: sh build.sh 可能花费时间较长，请耐心等待
* 注意事项：保证有sudo权限或以root身份登录操作系统

## 使用说明
* 首先参照环境准备，确认scrapy安装成功
* 由于ccqsc新加入了登陆，且有验证码，所以需要用户先登录 http://www.ccqsc.gov.cn/, 登陆后复制cookie作为命令的参数，比如这时的cookie是EEE7E90276C7318D892D642B99D9A359
* 在根目录执行爬虫执行命令: scrapy crawl ccqsc -a cookie="EEE7E90276C7318D892D642B99D9A359"， 如果有权限问题，在最前边加上sudo
* 执行命令的时候，浏览器不要关闭，因为cookie的过期时间是浏览会话结束时

## 下载文件的文件结构
* 每次下载，都会在data文件夹内创建一个以年份命名的文件夹，所有下载的文件都在这个目录，下载的文件则以它的批次号命名
* 关于json文件更新：每次执行时，如果发现该条命令要创建的文件夹（以日期或日期范围命名）存在，则将里面的文件全部删除，重新下载
